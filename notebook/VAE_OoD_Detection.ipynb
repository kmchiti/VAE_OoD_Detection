{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_OoD_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsgDYVqfTe0k"
      },
      "source": [
        "import lib.load_data as ld\r\n",
        "import lib.model as model\r\n",
        "import lib.validation as validation\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAPNLa6Y5CMn"
      },
      "source": [
        "**Fetch the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmHfXwJlWKPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f59c43-6bc1-4002-edda-89ba0638cb0c"
      },
      "source": [
        "\r\n",
        "print(\"fetching dataset!\") \r\n",
        "ld.download_mnist('dataset')\r\n",
        "ld.download_fmnist('dataset')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fetching dataset!\n",
            "creating  dataset/mnist\n",
            "Downloading data from http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9BjfwW-5MP_"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSbiV-57iPug",
        "outputId": "afe5e5e5-a5e4-42bc-b554-31de339603b2"
      },
      "source": [
        "\r\n",
        "print(\"training model!\")  # replace this with code to train the model\r\n",
        "latent_dim = 32\r\n",
        "original_dim = (28, 28, 1)\r\n",
        "batch_size = 100\r\n",
        "epochs = 30\r\n",
        "    \r\n",
        "#load data\r\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = ld.load_mnist('dataset',flatten=False)\r\n",
        "xf_train, yf_train, xf_test, yf_test, _, _ = ld.load_fmnist('dataset',flatten=False)\r\n",
        "\r\n",
        "#encoder\r\n",
        "encoder_inputs = model.keras.Input(shape=original_dim)\r\n",
        "z_mean, z_log_var = model.create_encoder(encoder_inputs, latent_dim)\r\n",
        "z = model.Sampling(z_mean, z_log_var)\r\n",
        "encoder = model.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\r\n",
        "#encoder.summary()\r\n",
        "\r\n",
        "#decoder\r\n",
        "latent_inputs = model.keras.Input(shape=(latent_dim,))\r\n",
        "decoder_outputs = model.create_decoder(latent_inputs, latent_dim)\r\n",
        "decoder = model.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\r\n",
        "#decoder.summary()\r\n",
        "\r\n",
        "vae = model.VAE(encoder, decoder)\r\n",
        "vae.compile(optimizer=model.keras.optimizers.Adam())\r\n",
        "vae.fit(x_train, epochs=epochs, batch_size=batch_size)\r\n",
        "#vae.fit(xf_train, epochs=epochs, batch_size=batch_size)\r\n",
        "  \r\n",
        "#store model\r\n",
        "if not (os.path.isdir('param')):\r\n",
        "  os.makedirs('param')\r\n",
        "vae.encoder.save(\"param/encoder_save\", overwrite=True)\r\n",
        "vae.decoder.save(\"param/decoder_save\", overwrite=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model!\n",
            "Epoch 1/30\n",
            "500/500 [==============================] - 36s 6ms/step - loss: 252.6548 - reconstruction_loss: 206.2020 - kl_loss: 5.2105\n",
            "Epoch 2/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 186.2735 - reconstruction_loss: 176.9937 - kl_loss: 6.7532\n",
            "Epoch 3/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 177.9383 - reconstruction_loss: 169.2544 - kl_loss: 7.1071\n",
            "Epoch 4/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 172.4771 - reconstruction_loss: 164.4605 - kl_loss: 6.9015\n",
            "Epoch 5/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 168.5942 - reconstruction_loss: 161.0883 - kl_loss: 6.7539\n",
            "Epoch 6/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 165.7438 - reconstruction_loss: 158.4742 - kl_loss: 6.7936\n",
            "Epoch 7/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 163.5702 - reconstruction_loss: 156.5498 - kl_loss: 6.8173\n",
            "Epoch 8/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 161.9459 - reconstruction_loss: 155.2381 - kl_loss: 6.7996\n",
            "Epoch 9/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 161.1783 - reconstruction_loss: 154.1042 - kl_loss: 6.8219\n",
            "Epoch 10/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 160.1763 - reconstruction_loss: 153.3164 - kl_loss: 6.7137\n",
            "Epoch 11/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 159.8773 - reconstruction_loss: 152.5351 - kl_loss: 6.5633\n",
            "Epoch 12/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 158.3547 - reconstruction_loss: 151.7958 - kl_loss: 6.3545\n",
            "Epoch 13/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 157.3264 - reconstruction_loss: 151.0341 - kl_loss: 6.1906\n",
            "Epoch 14/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 156.5517 - reconstruction_loss: 150.6282 - kl_loss: 6.1055\n",
            "Epoch 15/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 156.2351 - reconstruction_loss: 150.1104 - kl_loss: 6.0621\n",
            "Epoch 16/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 155.5884 - reconstruction_loss: 149.6951 - kl_loss: 6.0561\n",
            "Epoch 17/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 155.4246 - reconstruction_loss: 149.3094 - kl_loss: 6.0071\n",
            "Epoch 18/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 154.6358 - reconstruction_loss: 148.9841 - kl_loss: 6.0213\n",
            "Epoch 19/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 154.8860 - reconstruction_loss: 148.8102 - kl_loss: 6.0010\n",
            "Epoch 20/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 154.5229 - reconstruction_loss: 148.5536 - kl_loss: 6.0056\n",
            "Epoch 21/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 154.2415 - reconstruction_loss: 148.2115 - kl_loss: 6.0349\n",
            "Epoch 22/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.6352 - reconstruction_loss: 147.9584 - kl_loss: 6.0591\n",
            "Epoch 23/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.9122 - reconstruction_loss: 147.8215 - kl_loss: 6.0579\n",
            "Epoch 24/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.3963 - reconstruction_loss: 147.6689 - kl_loss: 6.0551\n",
            "Epoch 25/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.0875 - reconstruction_loss: 147.5259 - kl_loss: 6.0811\n",
            "Epoch 26/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.2822 - reconstruction_loss: 147.2808 - kl_loss: 6.0673\n",
            "Epoch 27/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 152.8296 - reconstruction_loss: 147.1207 - kl_loss: 6.0868\n",
            "Epoch 28/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 152.8631 - reconstruction_loss: 146.9051 - kl_loss: 6.1173\n",
            "Epoch 29/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 153.2488 - reconstruction_loss: 146.8399 - kl_loss: 6.1113\n",
            "Epoch 30/30\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 152.8382 - reconstruction_loss: 146.7781 - kl_loss: 6.1074\n",
            "INFO:tensorflow:Assets written to: param/encoder_save/assets\n",
            "INFO:tensorflow:Assets written to: param/decoder_save/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjqb3f6C521y"
      },
      "source": [
        "**Evaluate model and compute metrics and figures**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQJ0wjsbrzR",
        "outputId": "9348fd7c-e513-46a4-b420-008137a05084"
      },
      "source": [
        "\r\n",
        "print(\"evaluating model!\")\r\n",
        "t = -500\r\n",
        "#load model\r\n",
        "encoder = validation.keras.models.load_model(\"param/encoder_save\")\r\n",
        "decoder = validation.keras.models.load_model(\"param/decoder_save\")\r\n",
        "vae = model.VAE(encoder, decoder)\r\n",
        "vae.compile(optimizer=model.keras.optimizers.Adam())\r\n",
        "\r\n",
        "#load data\r\n",
        "_, _, _, _, x_test, y_test = ld.load_mnist('dataset',flatten=False)\r\n",
        "_, _, xf_test, yf_test, _, _ = ld.load_fmnist('dataset',flatten=False)\r\n",
        "xn_test, yn_test = ld.load_mnist_vs_fmnist('dataset',flatten=False)\r\n",
        "\r\n",
        "validation.plot_hist(x_in=x_test, x_out=xf_test, vae=vae)\r\n",
        "validation.plot_norm(x_in=x_test, x_out=xf_test, vae=vae)\r\n",
        "#validation.plot_hist(x_in=xf_test, x_out=x_test, vae=vae)\r\n",
        "#validation.plot_norm(x_in=xf_test, x_out=x_test, vae=vae)\r\n",
        "\r\n",
        "#validation.VA_spec(xf_test,yf_test)\r\n",
        "\r\n",
        "print(validation.accurcy (xn_test,vae, yn_test, t))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluating model!\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "0.878\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}